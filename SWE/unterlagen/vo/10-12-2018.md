# 10-12-2018

<!--TOC-->

## 

Pruefungsrelevant: Harmonic Mean bzw. F1 Score. Andrew Ng's ML Yearning Buch. 

## Grundlagen Neuronale Netzwerke

Idee aus den ~60ern, AI Winter durch ein Paper, was sagte, es ist alles BS - dann spaeter revived u.a. von DeepMind.

## Perceptron

Basically a function: has one or more inputs, one or more outputs. 

Z.B. Uni Acceptane: wenn 2\*Test + 1\*Grades - 18 > 0, ist der Student accepted. 

Perceptron haette dann Inputs und weights fuer TEST, GRADES und BIAS (-18)

Perceptron ist eine lineare Funktion: Summe von inputs \* entspr. weight + bias.

Output dieser Funktion kommt dann in eine step function, die 1 gibt, wenn input >= 0 und 0 sonst.

Das kann als weitere "Node" dargestellt werden, die den Output der ersten Node nimmt

Damit haetten wir ein Uni-Acceptance Perceptron.

Video: `Deep Learning Perceptron Definition`.

Ein simples NN waere dann eine Menge von Perceptrons, die mit denselben Inputs verbunden sind und deren Outputs auf irgendeine Weise kombiniert werden.

## Learning

im Falle von Perceptrons: Adjustieren der weights, sodass irgendeine cost function minimiert wird
