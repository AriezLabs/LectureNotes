# 07-01-2019

<!--TOC-->

## ML Ueberblick

Video: [Geoffrey Hinton - The Foundations of Deep Learning][1] als Zusammenfassung des Bogens von den 80ern bis jetzt.

How do you write a program that takes as input image data and returns a description of the image?

NNs: The basic neuron takes weighted inputs and applies some function. Gets hooked up to a network with different connections. These networks can do "anything" - just need to figure out how to set the weights, this is done by applying some change and seeing whether the result is improved. This is naive but works.

Problem with this approach: You have a billion weights. How do you do this more efficiently? With backpropagation. Send information back through the net to figure out: "a change in this weight would improve the result." Wie "memory" laut Prof.

Feedforward nets work well for speech and image recognition.

Later recurrent nets were introduced. Used for translation with encoder and decoder networks, encoder encodes a sentence in some language to a "thought"; decoder turns that into a sentence in its target language. These systems have zero preexisting knowledge. - no domain knowledge is required.

NN can be trained to diagnoes using labels generated by doctors and then outperform them. - understands and learns what's going on

#### Hauptpunkte

* no domain knowledge required
* Input scheint am besten zu funktionieren, wenn man ihn unveraendert reingibt - z.B. Sinuskurven bei audio to text (Translation besser mit Bitmaps von chinesischen Characters statt kodierten Symbolen)
* Vereinfacht Probleme wie Translation etc.: braucht keine Sammlung riesiger Tabellen

## Placebo Studie

[Studie][2] hat oeffentliches Dataset, wir untersuchen dies:

Legen Helper-Methoden an, um Features zu numerischen Attributen etc. zu konvertieren. Schauen nur bestimmte Features an, d.h. entfernen unerwuenschte Features (und $y$) mit `data.drop()`. Lassen `y = data['awt']` und fitten RandomForest drauf. 

Testen Classifier vs Regressor. Testen prediction von weight loss und betrachten feature importances, versuchen `cond` auf Basis des weight losses vorherzusagen. 

Zeigt: "informed" hat wenig Zusammenhang mit Gewichtsverlust. 

[1]: https://www.youtube.com/watch?v=zl99IZvW7rE
[2]: https://dash.harvard.edu/bitstream/handle/1/3196007/langer_excersiseplaceboeffect.pdf?sequence=1
