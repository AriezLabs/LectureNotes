# 12-03-2019

<!--TOC-->

## Introduction

* Throughput = #Queries/sec
* alles, was hilft, ist erlaubt
    * aber es gibt immer cost/benefit tradeoff - no free lunch
        * Kosten sind aber oft niedrig
* Ziele: 
    * allgemeine gundlegende "Bauteile" von DBs lernen
    * aber nichts spezifisches - nur Allgemeines, um in der Lage zu sein, Doku etc. zu verstehen
    * Experimente; Tuning-Prinzipien
    * anders als in DB2 hier mehr Blackbox-Verhalten (Praxis statt Theorie)

## Basic Principles of Tuning

* Notiz: `AVG` auf Folien steht fuer Average 
* Mathematische Modelle werden schnell zu komplex, **Prinzipien** helfen

5 Prinzipien:

1. Think globally, fix locally
    * *think globally*: "wie ein guter Arzt": ganzen Organismus anschauen, nicht nur Symptome beheben (Aspirin fuer Hirntumor)
    * *fix locally*: moeglichst geringer Eingriff, um side effects zu minimieren
    * Folien Bsp: high disk activity -> nicht einfach mehr Platten kaufen - vielleicht fehlt Index etc.
2. Partitioning breaks bottlenecks
    * wie im Verkehrsstau - Verstopfungen loesen durch schnellere Verbindung, oder Fahrer dazu bringen nicht immer um 8 zu fahren
    * *Partitioning* ist Verteilen der Anfragen auf mehr "Raum" oder auf Zeit
    * Partition in space: Aufteilung auf mehrere Platten/Systeme etc.
    * Lock contention on free list
        * *free list* haelt freien Platz im RAM
        * wenn ein Prozess sie konsultiert, ist sie *locked* - niemand anders kann darauf zugreifen
        * mehrere free lists, die RAM-Segmente verwalten, loesen das Problem: Prozess kann randomly auf eine von ihnen zugreifen
    * *Deadlock*: 2 Prozesse warten aufeinander, dass der andere seine Modifikation abgeschlossen hat, nichts ruehrt sich mehr
    * Partitioning funktioniert auch nicht immer - zB mit der free list: wenn fast alle voll sind, waehlen Threads lange randomly free lists
    * **Folgerung**: Partitioning am besten nur, wenn lokaler Fix nicht geht
3. Startup costs are high, running costs are low
    * e.g. Plattenzugriff: 1 Block lesen teuer, darauffolgender sehr guenstig - auf derselben Spur gelesene 64KB brauchen nur 2x laenger als 512B
    * Gilt sogar in RAM, seq read kann cached werden
        * Cache: es gibt cache lines, die immer ganz gelesen werden muessen
    * deswegen ist prefetching/caching wichtig
    * Netzwerk auch so: 1B Paket kostet ca genausoviel wie 1KB Paket
    * Queries: muessen parsed, optimiert etc werden, kostet selbst fuer kleine Queries viel
        * Compiled queries: Ergebnis von Optimierung etc. einer Query cachen, dann Parameter in die fertige Query einsetzen (eg PUT requests in Webdev - webapps haben ein paar fast immer gleiche queries) [prepared statement]
    * von Code zu DB connecten ist auch overhead. 
        * Connections koennen cached werden - pool von connections offen halten, fuer Query dann eine freie suchen und benutzen
    * **Folgerungen**: Layout auf der Platte ist extrem wichtig (Faktor 2+ moeglich), oft gebrauchte Queries vorkompilieren
4. Render on the server what is due on the server
    * Nur das, was Sinn macht, auf dem Server berechnen
    * Views sollten DB nicht blocken - eg Flugzeugsitzplatzreservierung: deine View zuhause kann nicht alle anderen Zugriffe blockieren
        * Mach nur eine Lesetransaktion draus, schreib spaeter separat
        * Problem: View evtl outdated
    * Tradeoffs:
        * Eine Anfrage schneller machen kann eine andere verlangsamen
        * Indizes brauchen Speicher

## Pruefung:

* Koennte diesmal schriftlich sein 
* Muendliche Pruefung: 20min Vorbereitung auf eine (eine Vorlesungseinheit abdeckende) Frage, 15min Gespraech dann + weitere Fragen
* Wird bewertet anhand technischer Korrektheit, Detailgrad/Vollstaendigkeit, Fachterminologie, vertiefende Fragen (Precision/recall: wieviel vond em Gesagten war richtig vs wieviel von dem, was gesagt haette werden koennen, wurd gesagt)
