# 19-03-2019

<!--TOC-->

## Query Tuning

ist das Umformen von Queries in andere equivalente Formen. Equivalenz ist dabei: 

* generieren die gleichen Mengen von Tupeln auf jeder *legalen* DB-Instanz
* legale DB-Instanzen erfuellen alle constraints, die im DB-Schema vorgegeben werden

Wir wollen Queries in equivalente Formen bringen, die schneller ausfuehrbar sind. Hat *keine* negativen side effects, weil sich die Semantik der Query nicht aendern sollte.

#### Wie werden queries verarbeitet?

1. Parser
    * liest String
    * gibt Ausdruck in relationaler Algebra zurueck (mit Selektion, Projektion, ...)
    * Output ist nicht eindeutig
2. Optimierer
    * nimmt Output vom Parser
    * baut daraus query plan
    * der Output haengt noch vom Input ab 
        * Wenn wir queries tunen wollen, muessen wir den Optimierer schlagen
        * kann sich in Zukunft aendern, aber heute lohnt sich deswegen Query Tuning noch
3. Execution engine
    * kuemmert sich um die Ausfuehrung

#### Umformungen

Wir nutzen Aequivalenzregeln zum Umformen der Queries: zB ist Selektion kommutativ. Es gibt viele solcher Regeln, muessen die nicht auswendig lernen

zB: Selektionen mit starker Selektivitaet lohnen sich iA zuerst auszufuehren. Es haengt aber davon ab, wie die Daten aussehen, ob die Optimierung tatsaechlich Sinn macht und Gewinn bringt.

Wir formen die Query wie gehabt mit einem Operatorbaum um.

#### Query Plan

kuemmert sich um die genaue Ausfuehrung der Query, z.B. welche Indices werden verwendet und welche Join-Algorithmen werden verwendet?

Jeder Ausdruck resultiert natuerlich in einem Haufen query plans, je nach Struktur der Daten, Indices, Groesse der Relationen etc.

Query plans finden ist der leichte Teil, das schwierige ist, in brauchbarer Zeit die zu finden, die schnell sind. (zB nur die Anzahl versch. Join-Moeglichkeiten waechst schneller als exponentiell)

Dies tun wir mit Heuristiken auf Basis des *Katalogs*: Statistiken, die die DB fuehrt - zB Anz Tupel in Relationen, Bloecke auf der Platte, wie verschieden die Werte in einer Relation sind etc. 
    * das ist relativ advanced - Histogramme ueber die Verteilung der Werte werden gefuehrt, weil bestimmte Werte oft vorkommen
    * Postgres haelt fest, wie oft die 100 oeftesten Werte vorkommen, nimmt an, der Rest ist gleichverteilt (Error ist dann gering weil die Anzahl dieser Werte einfach klein ist)

Auf Basis dessen koennen wir schaetzen, wie gross die Ergebnisse von Selektionen etc. sein werden (Histogramme werden dazu auch hergenommen)

Gibt auch size estimates fuer Projektionen - wird eig nur eine Spalte rausgeschmissen, aber bei `SELECT DISTINCT` werden potentiell Duplikate rausgeschmissen

Auch wenn Kostenabschaetzung insofern komplex ist, basiert sie nur auf Statistik und die wird nur ab und an neu berechnet (zB Postgres `ANALYZE` Befehl) - nach Einfuegen vieler Werte ist die Statistik ggf daneben, Optimierer rechnet dann mit falschen Zahlen.

#### Choosing the cheapest plan

schwierig, weil es so viele Plaene gibt. Gluecklicherweise sind die meisten trash:

* Pruning: Plaene, die nicht mehr der billigste sein koennen, werden abgebrochen (wir brauchen ja nicht die Kosten von allen Plaenen, sondern nur den billigsten)
* wenn billigste Teilplaene gefunden sind, werden fuer den gesamten Plan natuerlich nur Plaene betrachtet, die diesen Teiplan beinhalten
* Heuristics - Selektionen ASAP durchfuehren, dann Projektionen; kartesische Produkte vermeiden 
    * Heuristiken koennen daneben liegen - Kreuzprodukte koennen schneller als Joins sein

IRL werden mit Heuristiken vielversprechende Plaene gesucht und dann der Plan mit der besten Kostenabschaetzung darunter mit Pruning ausgewaehlt. Deswegen sind Optimierer nicht perfekt


Wir koennen dem Optimierer aber das Leben leichter machen:

#### Problematic Queries

zB langsame Queries, wo ein relevanter Index nicht benutzt wird.

Allgemein problematische Dinge: [vgl. DB Tuning Buch, p. 143ff.]

* `DISTINCT`: erzwingt Sortieren oder Hashing
* Subqueries sind ein grosses Problem - allgemein vermeiden
    * Optimierer sind gut in Join-Optimierungen, Subqueries erlauben das iA nicht
* Temporaere Tabellen: Zwischenergebnis in einer temporaeren Tabelle ablegen und dann spaeter damit weiterarbeiten. Nehmen dem Optimierer Moeglichkeit, seine Arbeit zu tun
    * erzwingt order of operations
    * loest Katalog-Updates aus
    * Index evtl nicht verwendbar
    * besser: alles in eine query


