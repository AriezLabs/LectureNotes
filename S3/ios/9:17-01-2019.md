# 17-01-2019

<!--TOC-->

## Speicher

* address space (linear)
* addressiert storage
* in modernen Programmiersprachen wird address space von konkreten Speicheradressen zu Variablennamen wegabstrahiert
* in Selfie: byte adressed, word aligned.
* *memory management problem*
    * Adressraum muss verwaltet werden: welche Adressen werden gerade verwendet und welche nicht?
    * Unterscheidung used/free
    * Memory management: diese Unterscheidung laufend irgendwo irgendwie festhalten
    * Speicher ist ja in static/dynamic unterteil (static haelt Code und Daten), static ist also immer used, dynamic teil ist im Stack und Heap besetzt
    * Stack fragmentiert nicht
        * Speicher im Stack wird bei Funktionscalls alloziiert
    * Heap-Speicher wird explizit alloziiert - in C `malloc`, in Java `new`
        * `malloc` etc geben prinzipiell nur Speicheradresse zurueck, fuer die gelten soll, dass diese Adresse vorher ungenutzt war
        * `malloc` ist also ein "Zahlengenerator", der free mem-Adressen findet
    * in selfie: gibt kein `free`, Speicher wird einfach fortlaufend alloziiert. Ist simpel
        * `malloc`/`free` bzw. wie verwaltet man used/free memory ist insane kompliziert
    * Java hat auch kein `free` - Speicher wird freigegeben, wenn kein Pointer mehr auf eine Adresse zeigt

**Verknuepfung von Address Space und Storage - ist nicht unbedingt 1:1 und ist Kirschs Lieblingsthema**

* Wir haben zB 4GB RAM und wollen darauf mehrere Sachen ausfuehren (irgendwelche Binaries von irgendwelchen Leuten, wo sich jeder Entwickler dachte dass er den ganzen Speicher fuer sich hat)
* Loesung: Abstrahieren Adressraum zu einem virtuellen Adressraum
    * **Virtual Memory** ist *nur* ein Adressraum, der kann groesser oder kleiner sein als das was wir tatsaechlich zur Verfuegung haben
    * Virtual Memory Adressraeume sind mit 48bit implementiert, auch auf 64bit-Maschinen
    * jeder Prozess kriegt einen virtuellen Adressraum
    * **Segmentation**: einfachste Methode, virtual mem zu implementieren
        * zB jede Anwendung kriegt ein $x$ MB grosses Segment im tatsaechlichen Speicher. 
        * Das Segment kann dann von der Anwendung wie komplett eigener Speicher verwendet werden. 
        * `load`-Instruktionen innerhalb der Anwendung muessen mit virtuellen Adressen arbeiten
            * sind dann zu physischen Adressen konvertierbar, indem man einfach die Startadresse des Speicherblocks der Anwendung draufaddiert
            * Das Konvertieren macht Hardware - Memory Management Unit - weil so oft solche *address translations* stattfinden (bei jedem Befehl)
                * Bei Versuch, auf Adresse ausserhalb des Segments zuzugreifen,  kommt Segmentation Fault - ob das auftritt, wird auch in Hardware ueberprueft
    * Perfekte Virtualisierung des Speichers: als haette man die ganze Maschine fuer sich, obwohl das nicht so ist
    * Wenn man zwischen Anwendungen switcht, muss nicht nur der Program Counter veraendert werden, sondern auch das aktuelle Segment etc.
    * vor 20-30 Jahren war Segmentation der Stand der Technik
* Heute: wollen groessere virtuelle Adressraeume (nicht nur 100MB, sondern [viel] groesser als physischer Speicher sogar)
* wie kriegen wir das hin? - **Paging** oder Paged Memory
    * machen uns virtuellen 2^48 bit Adressraum, unterteilen in 4KB *Pages*.
    * unterteilen physischen Speicher in eine bestimmte Anzahl 4KB *page frames*
    * haben eine *Page Table* fuer jeden virtuellen Adressraum - prinzipiell eine Tabelle, implementiert als Array indiziert ueber die Pages: mappt $0$-te Page zu irgendeinem page frame
    * Page Table ist praktisch leer. Nur verwendeter Speicher hat ein Mapping - unbenutzte Eintraege haben nichtmal einen Eintrag. Oben im virtuellen Adressraum ist Stack etc, unten Code und Daten -> Page Table ist unten voll und oben und hat dazwischen Terabytes freien Speicher
    * Welche Datenstruktur fuer Page Table? Intuitiv: Baum mit einer Ebene - ein Leaf fuer unteren Teil der Tabelle, ein Leaf fuer oberen Teil, Root die beide verbindet.
        * Leaves sind dann "Subtabellen" - auch als 4KB  Page Frames implementiert. -> keine Fragmentierung
        * in der Praxis ist der Baum tiefer (3-4 Ebenen) und Konstruktion wird vom OS uebernommen, waehrend Lookup in Hardware implementiert ist

in der Praxis wird beim Starten eines Programms  gar keine Page Table angelegt - nur beim Fetch der ersten Instruktion wird angefangen, die Table zu bauen. d.h. der eigentliche Start kostet nichts, nur wenn tatsaechlich angefangen wird etwas zu machen - das ist weil oft viele Teile des Codes gar nicht ausgefuehrt wurden etc.

**Page Replacement Problem** - welcher Frame kann rausgeschmissen werden und mit dem ersetzt, was man gerade braucht? Wir wollen den Frame austauschen, den wir am Spaetesten erst wieder brauchen.

* Austauschen setzt Page Replacement Algorithm voraus
* *Swapping*: Frame wird in persistenten Speicher geswappt
* wie finden wir einen sinnvollen Frame zum Swappen? - least recently used. Ist nur Heuristik anhand einer Eigenschaft typischer Software: *locality*. Die hat 2 Aspekte: *temporal* und *spatial*. 
    * Temporal sagt das VErhalten von Software ist temporally local gdw die Wslkeit dass auf eine Adresse, auf die gerade zugegriffen wurde, in naher Zukunft wieder zugegriffen wird, hoch ist.
    * Spatial sagt hohe Wahrscheinlichkeit fuer Zugriffe auf Adressen, die nahe beieinander sind
    * sagt intuitiv, dass Code sich irgendwie an einem Fleck/Hotspot bewegt.
    * LRU Strategie funktioniert nicht immer gut - MRU macht Sinn bei Prozessen, die zB nur Speicheradressen lesen und danach nie wieder anfassen. Ist nur beste Heuristik nach forensischer analyse
    * das alles passiert im Kernel

**Shared Memory** ist zB, wenn zwei Pages von unterschiedlichen Prozessen auf denselben Page Frame gelegt werden. So kommunizieren Prozesse im Endeffekt, fuehrt dann zu Concurrency Problems etc etc.

**Copy On Write**: Prozesse, die sich forken, teilen anfangs ihr Memory komplett (page tables sind 1:1 Kopien), nur wenn einer in "seinen" Speicher schreibt, kriegt er seine "eigene" Page

Compiler
Scheduled: 05.03.2019 at 10:00 to 12:00
Switching frequency von Prozessen auf irgendeinem Laptop: ~10ms - das ist niedrig. Umschaltkosten werden zu teuer, wenn man oefer switcht
