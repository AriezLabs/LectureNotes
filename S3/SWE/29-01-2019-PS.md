# 29-01-2019-PS

<!--TOC-->

## Backpropagation

Betrachten Error als Differenz von dem tatsaechlichen Output eines Neurons und dessen gewuenschten Outputs.

Betrachten Gewichte dieses Neurons: groessere Gewichte haben mehr Einfluss auf den Fehler gehabt -> tragen mehr "Schuld".

Damit ist der Fehler prinzipiell auf die vorherige Schicht von Neuronen zurueckpropagiert. Fehler von Neuronen in der vorherigen Layer sind Sumem der gewichteten Fehler ihrer Kanten.

Im Python-Code sind inputs und targets Vektoren

hidden inputs/outputs sind der forward propagation part

Fehler ist Targets minus das was wir ausgerechnet haben

Backpropatgaion ist Aufteilung der Gewichte

Anpassung der Gewichte aka die cancer zeile: 

Gradientenabstieg. Versuchen Minimum zu finden: Wie muss ich die Gewichte aendern, damit der Fehler minimiert wird? 
